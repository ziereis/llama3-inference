### super small llama3

fully fledged llama3 inference in a couple lines of python with KV cache and greedy token generation.
Tokenizer file is copy pasted from the meta llama3 repo.
