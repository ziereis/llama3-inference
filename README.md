### super small llama3

fully fledged llama3 inference in a couple lines of python with KV cache and greedy token generation.
Tokenizer file is copy pasted from the meta llama3 repo.


sources:
https://github.com/naklecha/llama3-from-scratch
https://github.com/meta-llama/llama3
